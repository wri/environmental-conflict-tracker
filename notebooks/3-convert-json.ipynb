{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Introduction\n",
    "## 1.0 Package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import json\n",
    "from newsplease import NewsPlease"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Definitions\n",
    "\n",
    "## 2.0 Parameter definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'indonesia'\n",
    "year = 2019\n",
    "month = 1\n",
    "path = \"../data/{}/\".format(country)\n",
    "metadata_path = (path + \"metadata/\" + str(year) + \"/\"\n",
    "                 + str(month).zfill(2) + \".csv\")\n",
    "\n",
    "fulltext_path = (path + \"text/\" + str(year) + \"/\"\n",
    "                 + str(month).zfill(2) + \"/\")\n",
    "\n",
    "json_path = (path + \"json/\" + str(year) + \"/\"\n",
    "                 + str(month).zfill(2) + \"/\")\n",
    "\n",
    "if not os.path.exists(json_path):\n",
    "    os.makedirs(json_path)\n",
    "\n",
    "cols_to_keep = ['Actor1Code', 'Actor1Name', 'Actor2Code', 'IsRootEvent', 'EventCode', 'CAMEOCodeDescription',\n",
    "                'EventRootCode', 'QuadClass', 'GoldsteinScale', 'NumMentions', 'AvgTone', 'ActionGeo_FullName',\n",
    "                'ActionGeo_Lat', 'ActionGeo_Long', 'SOURCEURL', 'title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_obj(idx: int, path: str = fulltext_path) -> \"NewsPlease object\":\n",
    "    idx = str(idx).zfill(5)\n",
    "    with open(path + idx + \".pkl\", \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def save_obj(obj: dict, idx: int, path: str = json_path) -> None:\n",
    "    idx = str(idx).zfill(5)\n",
    "    with open(path + idx + \".pkl\", 'wb') as fp:\n",
    "         pickle.dump(obj, fp)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Execution\n",
    "\n",
    "Merge the `dataframe` row with the `NewsPlease` text to create a `JSON` object as such:\n",
    "\n",
    "```javascript\n",
    "{ \"id\": \"00001\",\n",
    "  \"country\": \"IN\",\n",
    "  \"url\": \"https://\",\n",
    "  \"date\": \"MM-DD-YYYY\",\n",
    "  \"full_text\": string,\n",
    "  \"article_title\": string,\n",
    "  \"number_actions\": int,\n",
    "  \"actions\": {\n",
    "      1: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n",
    "      2: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n",
    "      3: {'latitude', 'longitude', 'action_type', \"goldstein\", ...},\n",
    "          },\n",
    "  }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`mapping_dictionary` maps: `{ \"url_idx\": \"dataframe_idx\"}`, `url_idx.zfill(5)` is the file name of the NewsPlease article in the `texts` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "action_dict = dict(zip(cols_to_keep[:-2], [None] * (len(cols_to_keep) - 2)))\n",
    "\n",
    "base_dict = {\n",
    "    'id': None,\n",
    "    'country': None,\n",
    "    'url': None,\n",
    "    'full_text': None,\n",
    "    'article_title': None,\n",
    "    'number_actions': None,\n",
    "    'actions': dict()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(metadata_path)\n",
    "\n",
    "urls = data['to_scrape'].unique()\n",
    "mapping_dictionary = {}\n",
    "for i, val in enumerate(urls):\n",
    "    match = data.index[data['to_scrape'] == urls[i]].tolist()\n",
    "    mapping_dictionary[i] = match "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, val in enumerate(urls):\n",
    "    if os.path.exists(fulltext_path + str(i).zfill(5) + \".pkl\"):\n",
    "        fulltext = load_obj(i)\n",
    "        metadata = data.iloc[mapping_dictionary[i]]\n",
    "        metadata = metadata[cols_to_keep].reset_index()\n",
    "\n",
    "        item_dict = base_dict.copy()\n",
    "        item_dict['id'] = str(i).zfill(5)\n",
    "        item_dict['country'] = country\n",
    "        item_dict['url'] = fulltext.url\n",
    "        item_dict['article_title'] = fulltext.title\n",
    "        item_dict['date'] = fulltext.date_publish\n",
    "        item_dict['language'] = fulltext.language\n",
    "        item_dict['number_actions'] = len(metadata)\n",
    "        item_dict['text'] = fulltext.text\n",
    "\n",
    "        actions_dict = {}\n",
    "        for action in range(len(metadata)):\n",
    "            metadata_i = list(metadata.iloc[action])\n",
    "            action_dict_i = dict(zip(cols_to_keep[:-2], metadata_i))\n",
    "            actions_dict[action] = action_dict_i\n",
    "\n",
    "        item_dict['actions'] = actions_dict\n",
    "        save_obj(item_dict, i, json_path)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "policy-toolkit",
   "language": "python",
   "name": "policy-toolkit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
